## Authors
<table>
    <td align="center">
      <a href="https://github.com/heitorabreu">
        <img src="https://avatars.githubusercontent.com/u/96392593?v=4" width="100px;" alt="Foto do Penha"/><br>
        <sub>
          <b>Heitor Abreu</b>
        </sub>
      </a>
    </td>
    <td align="center">
      <a href="https://github.com/vesrozeno">
        <img src="https://avatars.githubusercontent.com/u/58575975?v=4" width="100px;" alt="Foto do Vitor"/><br>
        <sub>
          <b>Vitor Rozeno</b>
        </sub>
      </a>
    </td>
</table>

# lexical-analyzer-using-flex

The lexical analyzer plays an essential role in a compiler, being responsible for transforming the source code of the program into semantic units called tokens. Additionally, it removes whitespace and comments, performs initial syntax checks, builds the symbol table for scope control, generates error messages for lexical issues, and in some cases, even contributes to lightweight optimizations. This first phase is crucial because it prepares the groundwork for the subsequent stages of the compiler, directly influencing the quality and efficiency of the object code generated from the source code.
# Execution
1. In the folder where the files are located, execute:
`flex lexer.c`
2. Then, compile the generated ".c" code using the following command:
`gcc lex.yy.c -lfl -o lexer`
3. Finally, run the program by passing the "teste.txt" file as a parameter:
`./lexer teste.txt`
# Language Definition 
Let the regular expressions be as follows: 
```
E1: (0-9)+ 
E2: (a-zA-Z)(a-zA-Z0-9_)* 
E3: ( )+ |( \n)+ |( \t)+ | (\t\r) + 
E4: ( + | - | * | / | % | ++ | -- ) 
E5: ( == | < | > | <= | >= | != ) 
E6: ( && | || | ! ) E7: ( = ) 
E8: ( " | ' |∶ | ( | ) | { | } | ,| ; | .| " | & | [ | ] )
```
Thus, the accepted language is defined as: ***E1|E2|E3|E4|E5|E6|E7|E8***
# lexer.l
In this file, the regular expressions that are present in the language are defined, such as the expressions for variable names, numbers, operators, and symbols, following the syntax of the flex generator.

```flex
NUMERO [0-9]+
IDENTIFICADOR [a-zA-Z][a-zA-Z0-9_]*
ESPACO [ ]+
QUEBRA_DE_LINHA [\n]
TAB [\t]+
CARRIAGE_RETURN [ \t\r]
OPERADOR_ARITMETICO "+"|"-"|"*"|"/"|"%"|"++"|"--"
OPERADOR_RELACIONAL "=="|"<"|">"|"<="|">="|"!="
OPERADOR_LOGICO "&&"|"||"|"!"
OPERADOR_ATRIBUICAO "="
SIMBOLO "\""|"'"|":"|"("|")"|"{"|"}"|","|";"|"."|"'"|"&"|"["|"]"
```

Expressions for ignoring both block and inline comments have also been added to the analysis; furthermore, comments without an end in block comments would trigger an error:

```flex
"/*" {BEGIN(COMMENT);}

<COMMENT>"*/" { BEGIN(INITIAL); }

<COMMENT>.|\n

<COMMENT><<EOF>> {fprintf(yyout, "\t(ERRO - COMENTARIO SEM FIM)\n");return 0;}

"//".*                 { /* Ignorar comentários de linha */ }
```

Expressions have been added to detect errors, such as invalid variable names (starting with numbers or "_") and unknown characters.

```flex
"_"{IDENTIFICADOR}
|{NUMERO}{IDENTIFICADOR}
|"_"{NUMERO}{IDENTIFICADOR}
|"_"{IDENTIFICADOR}
|{NUMERO}"_"{IDENTIFICADOR} 
{fprintf(yyout, "\t(linha: %d, ERRO - IDENTIFICADOR INVALIDO: %s)\n", yylineno, yytext); }

.  {fprintf(yyout, "\t(linha: %d, ERRO - CARACTER DESCONHECIDO: %s)\n", yylineno, yytext); }
```

Tabs, spaces, and line breaks will be ignored during the analysis. In the "main" function of the file, a file (passed as a parameter) will be read, and the lexical analysis will be written to an "output.txt" file.
# teste.txt
The file "teste.txt" sent is as follows:
```c
int main()
{
    int abc;
	int 1abc, _abc, _1abc; //variáveis inválidas
    abc = 24 + 32;
    if(abc >10)
        printf("hello");
    else
        printf("no hello");

	//teste comentário linha
	/*teste 
	comentário 
	bloco*/
	
	((([[[}}}{{]]//teste de tokens seguidos
	
	@@@@ //teste caracter desconhecido
	
	/* teste - comentário sem fim (Erro)
}
```
In it, the intention was to test valid tokens, invalid tokens, and comments. You can edit it in any way you prefer for analysis.
# output.txt
The "output.txt" file generated by the analysis of the "teste.txt" file is as follows:
```
(linha: 1, IDENTIFICADOR: int)

(linha: 1, IDENTIFICADOR: main)

(linha: 1, SIMBOLO: ()

(linha: 1, SIMBOLO: ))

(linha: 2, SIMBOLO: {)

(linha: 3, IDENTIFICADOR: int)

(linha: 3, IDENTIFICADOR: abc)

(linha: 3, SIMBOLO: ;)

(linha: 4, IDENTIFICADOR: int)

(linha: 4, ERRO - IDENTIFICADOR INVALIDO: 1abc)

(linha: 4, SIMBOLO: ,)

(linha: 4, ERRO - IDENTIFICADOR INVALIDO: _abc)

(linha: 4, SIMBOLO: ,)

(linha: 4, ERRO - IDENTIFICADOR INVALIDO: _1abc)

(linha: 4, SIMBOLO: ;)

(linha: 5, IDENTIFICADOR: abc)

(linha: 5, OP. ATRIBUICAO: =)

(linha: 5, NUMERO: 24)

(linha: 5, OP. ARITMETICO: +)

(linha: 5, NUMERO: 32)

(linha: 5, SIMBOLO: ;)

(linha: 6, IDENTIFICADOR: if)

(linha: 6, SIMBOLO: ()

(linha: 6, IDENTIFICADOR: abc)

(linha: 6, OP. RELACIONAL: >)

(linha: 6, NUMERO: 10)

(linha: 6, SIMBOLO: ))

(linha: 7, IDENTIFICADOR: printf)

(linha: 7, SIMBOLO: ()

(linha: 7, SIMBOLO: ")

(linha: 7, IDENTIFICADOR: hello)

(linha: 7, SIMBOLO: ")

(linha: 7, SIMBOLO: ))

(linha: 7, SIMBOLO: ;)

(linha: 8, IDENTIFICADOR: else)

(linha: 9, IDENTIFICADOR: printf)

(linha: 9, SIMBOLO: ()

(linha: 9, SIMBOLO: ")

(linha: 9, IDENTIFICADOR: no)

(linha: 9, IDENTIFICADOR: hello)

(linha: 9, SIMBOLO: ")

(linha: 9, SIMBOLO: ))

(linha: 9, SIMBOLO: ;)

(linha: 16, SIMBOLO: ()

(linha: 16, SIMBOLO: ()

(linha: 16, SIMBOLO: ()

(linha: 16, SIMBOLO: [)

(linha: 16, SIMBOLO: [)

(linha: 16, SIMBOLO: [)

(linha: 16, SIMBOLO: })

(linha: 16, SIMBOLO: })

(linha: 16, SIMBOLO: })

(linha: 16, SIMBOLO: {)

(linha: 16, SIMBOLO: {)

(linha: 16, SIMBOLO: ])

(linha: 16, SIMBOLO: ])

(linha: 18, ERRO - CARACTER DESCONHECIDO: @)

(linha: 18, ERRO - CARACTER DESCONHECIDO: @)

(linha: 18, ERRO - CARACTER DESCONHECIDO: @)

(linha: 18, ERRO - CARACTER DESCONHECIDO: @)

(ERRO - COMENTARIO SEM FIM)
```
In it, you can see the analyzed line and the obtained token. Errors are displayed in a format further to the right (tab-indented) to make them stand out in the analysis.

